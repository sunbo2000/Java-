### Redis 数据结构

#### 为什么使用 Redis?

- 读写性能优异
- 丰富的数据类型
- 支持持久化



#### Redis 有哪些数据类型?

五种基本数据结构

- String 字符串, 可以是字符串也可以是整数, 对整数可以进行自增自减操作. 使用字符串类型时的编码方式为 embstr 或 row(底层都是 SDS 动态动态字符串), 当字符串长度小于 44 字节时使用 embstr 编码, 不需要重新开辟空间, 此时 RedisObject 和 SDS 是一段连续空间. 当字符串长度大于 44 字节时, 采用 row 编码, row 编码的 SDS 需要重新开辟空间, RedisObject 的指针指向这个 SDS. 使用数字类型时的编码方式为 int, 底层的实现方式是 long, 直接保存在 RedisObject 的 ptr 里
- List 列表, `可以从两端加入或弹出元素, 读取单个或多个元素, 类似于 Java 中的 LinkedList`, List 的编码方式为 QuickList 快表的形式, 快表是双向链表和压缩链表的集合, 双向链表的结点是 ziplist 压缩链表, 拥有 ziplist 占用空间小的优点, 同时避免了申请大量的连续内存. 在 Redis 3.2 之前 Redis 是使用 双向链表或者压缩链表实现 List
- Hash 散列: 包含对键值对的无序列表, 可以对对象中的每个字段独立存储, 类似于 HashMap. 底层的编码方式是 ziplist 压缩链表或 dict 字典. 当存储的数据较少时, 使用 ziplist 进行存储, 随着数据的增加会转而使用 dict 存储. 默认当 ziplist 的元素个数大于 512 或某个元素大小大于 64 字节就会使用 dict 存储. 
- Set 集合: 一个无序不重复的集合. 底层的编码为 IntSet 或 Dict(为 Dict 时, value 全为 null),当存储的所有元素都是整数, 并且元素不多时, 底层采用 IntSet `有序整数集`编码, 当元素个数增多时会变为 Dict 编码
- ZSet 有序集合: 和散列相似, 存储的是键和分数的映射, 会根据它的分数对其进行排序. 可以根据键查相应分数. 底层采用 ziplist 编码或者 Dict 和 SkipList 组合编码, 当元素个数较少时使用 ziplist 进行编码, ziplist 是连续内存, 所以键和分数是两个连续的 entry, key 在前, score 在后. 按照分数升序排序. 当元素个数大于 128 或者单个元素大于 64 字节是就会升级为 Dict 字典加 SkipList 跳表的形式编码. Dict 为其提供了随机访问分数的能力, SkipList 为其提供了排序的能力.  

三种特殊数据结构

- HayperLogLogs(基数统计): 是一种概率算法, 它能统计数据集的大小但是不存储数据本身
- Bitmap(位图): 存储的是连续的二进制数字 0 和 1, 通过 Bitmap 只需要通过一个 bit 位来表示某个元素对应的值或状态. Bitmap 底层使用 String 来实现的, 所以最大上限是 512 MB( 2^29 B), 换算成 bit 是 2 ^ 32 bit 
- Geospatial (地理位置): 基于 ZSet 实现, 存储地理位置信息, 经纬度



#### Redis 的对象机制(RedisObject)?

>Redis 的数据库中存储的是从 key 到 object 的映射关系, 在这个映射关系中, key 是 String 类型的, 而  value 可以是多种类型的, 从 Redis 内部来看数据库内的映射关系是用一个 dict 字典来维护的, 为了能在同一个 dict 内存储不同的 value, 就需要用一种统一的数据结构, 这个数据结构就是 RedisObject.



#### Redis 底层有哪些数据结构?

- 简单动态字符串 - SDS

- 整数集 - IntSet

- 压缩列表 - ziplist
- 快表 - quicklist
- 字典 - dict
- 跳表 - skiplist



#### 为什么要使用 SDS?

C 语言原生的字符串有很多问题, 比如获取长度是要计算, 不可以修改, 并且二进制不安全. 为此 Redis 定义了 SDS 对 C 语言的字符串进行了封装, 

- 它支持动态扩容
  - 字符串小于 1M 时,扩展为 2 * [len(old) + len(add)] + 1
  - 大于 1M 时, 扩展后为 [len(old) + len(add)] + 1M + 1, 
- 减少内存的分配次数.
- 并且是二进制安全的.



#### 知道 IntSet 吗?

IntSet 是 Redis 集合的一种实现方式, 它基于整数数组实现, 它有三种编码方式分别通过 2字节, 4字节, 8字节来存储数据, 会根据集合内元素的大小找到合适的编码方式. 为了查找方便, IntSet 中的元素按升序排序保存在数组里, 查找的时候使用二分查找.



#### 知道 Dict 吗?

Dict 字典, 散列数据结构, 存储 key - value 型的数据, Redis 中大量用到了这种数据结构. 字典由三个重要的部分组成, 分别是 字典Dict, 哈希表DictHashTable, 哈希结点dictEntry. 字典中有两个哈希表, 一个用于主要存储数据, 另一个主要用于重新哈希. 哈希表采用拉链法解决哈希冲突. 

哈希表的扩容因子为 (used/size), 每次新增数据时都会检查扩容因子, 如果扩容因子大于1且没有进行 RDB 持久化并且没有进行 aof 重写时直接扩容, 如果正在持久化且扩容因子大于了5也会扩容. 

哈希表的扩容采用的是渐进式重哈希, 避免扩容过程中对性能造成影响, 扩容的过程:

- 设置新的size:
  - 如果是扩容, 新的 size 是第一个大于等于当前元素个数加一并且是2的n次方的那个数
  - 如果是缩容, 新的 size 是第一个大于等于当前元素个数并且是2的n次方的那个数(扩容因子为0.1时)

- 按照新的数组大小申请空间, 创建哈希表赋值给 ht[1]
- 将 rehashidx 设为 0, 表示开始渐进式重哈希
  - 在 rehash 期间, 新增数据直接在 ht[1] 中进行, 所有的删改查操作都会顺带的将 ht[0] 中的元素转移到 ht[1] 内, 当 ht[0] 内所有的元素都转移到 ht[1] 中之后, 将 rehashindex 设为 -1, 表示 rehash 结束



#### 什么是 ZipList?

ZipList 是一种特殊的双向链表, 但是它并不是引用指针, 因为指针比较占用内存, 它使用了一段连续的内存, 并且每一个结点都保存了前一个结点的长度(如果前一个结点小于254字节采用一个字节记录, 如果大于254字节就采用5个字节记录). 这样就可以通过内存来计算前一个结点和后一个结点的起始位置, 达到了双向链表的效果.



#### 什么是 ZipList 的连锁更新问题?

因为 ZipList 的结点中记录前置结点长度会用到1个字节或者5个字节, 一个结点的长度本来小于 254 字节, 但更新后超出了 254 字节, 那么它后置结点就要增加 4 个字节来记录前置结点长度, 如果它在增加了 4 个字节后也超出了 254 字节, 它的后置结点也要修改, 就这样可能造成后续一些列的结点都要更新. 这就是连锁更新问题.



#### 什么是 QuickList?

linkedlist 不需要连续内存, 但是占用空间大, ziplist 占用空间小但是需要连续内存, 如果占用内存很多申请内存的效率很低. QuickList 是一个双向链表, 不过双向链表的每一个结点都是一个 ziplist. 避免了 ziplist 需要大量连续内存和 linkedlist 占用空间大的问题. 为了进一步压缩体积, quicklist 还会对中间的 ziplist 结点进行压缩存储. 



#### 什么是 SkipList ?

Redis 里面的跳跃表, 首先它是一个双向链表, 但是它和传统的链表有所不同, 它的结点可能包含了多个指针,每个指针的跨度不同, 这些指针保存在 level 数组里, 数组的大小代表它的指针的层数, level 数组的层数在 1 到 32 中生成. 它的每个结点都包含 val 值和 score 分数, 元素会按照分数升序排序. 查找元素时通过不同跨度匹配, 查找效率很高. 



#### 为什么用跳表不用树?

- 跳表的增删改查效率和红黑树相似, 但是实现更加简单
- 跳表做范围查询很友好
- 平衡树为了保持平衡在增删操作时需要旋转来保持平衡, 跳表无需这些操作



#### Redis 一个字符串类型的值存储最大容量是多少?

512BM



### Redis 优势

#### 为什么 Redis 这么快?

- Redis 完全基于内存, 绝大部分操作都都是纯内存操作, 非常快速
- Redis 内置了多种优化后的数据结构, 性能很高
- Redis 是单线程的, 避免了不必要的上下文切换的开销, 也不存在各种锁问题.
- Redis 使用了非阻塞的 IO 多路复用模型



#### Redis 的线程模型?

Redis 内部使用了文件事件处理器, 文件事件处理器是单线程的, 使用 IO 多路复用程序来同时监听多个 socket, 多个 socket 可能会产生多种操作对应不同的文件事件. IO 多路复用程序会将产生的文件事件放入队列中排队, 文件事件分派器每次从队列中取出一个事件交给对应的事件处理器处理(连接请求处理器, 命令请求处理器, 命令回复处理器).



文件事件处理器包含四个部分:

- 多个 socket

- IO 多路复用程序

- 文件事件分派器

- 事件处理器(连接请求处理器, 命令请求处理器, 命令回复处理器)

  ![文件事件处理器](assets/redis-event-handler.png)



#### 为什么 Redis 是单线程的?

- 抛开持久化不谈, Redis 是纯内存操作, 执行速度非常快, 它的性能瓶颈是网络延迟而不是执行速度, 因此多线程并不能带来很大的性能提升
- 多线程会导致过多的线程上下文切换, 带来不必要的开销
- 引入多线程必然要涉及线程安全问题, 这就涉及到线程锁这样的安全手段, 实现起来复杂, 可能还会造成性能的折扣

> Redis4.0 的时候就加入了多线程, 主要是异步处理一些耗时较久的任务, 比如异步删除命令



#### Redis 6.0 为什么引入多线程?

Redis 6.0 引入多线程主要是为了提高网络 IO 读写性能, 更加充分的利用多核 CPU 资源(主线程只会用一个核), 但是只是在网络读写上使用了多线程, 核心的命令处理部分还是单线程的. 6.0 的多线程也是默认关闭的.



### 持久化机制



#### Redis 有哪些持久化机制?

1. RDB 持久化方式, RDB 是生成一个内存快照, 把内存数据以二进制的方式保存在磁盘上. 当 Redis 重启后从磁盘读取快照文件, 恢复数据. 

   - 优点是恢复速度快, 二进制文件的文件体积小
   - 缺点是执行 RDB 的周期很难把控, 两次 RDB 之间的数据丢失, 如果频繁执行会影响性能, 偶尔执行的话又容易丢失很多数据. 

   

2. AOF 持久化方式, AOF 是一个写后日志, 每次执行命令后将命令追加到 aof 文件, Redis 重启时会执行官 aof 文件中的每条命令来重建内存数据. 

   - 为什么是写后日志? Redis 为了性能, 记录 aof 日志时没有检查语法是否正确, 如果先记录日志,可能在日志中记录错误命令

   - 记录 AOF 日志时有三种同步策略

     - Always 同步刷盘, 每次写入命令都进行刷盘, 优点是可靠性高, 缺点是性能消耗大
     - everysec 先将命令放进缓冲区, 每秒执行一次刷盘操作, `默认`的方案, 可靠性适中, 性能消耗适中
     - No 由操作系统写, 将命令先放进缓存区, 由操作系统决定什么时候刷盘, 可靠性差, 性能好

   - 优点是数据完整性高, 对系统资源的占用低, 主要占用的是 IO 资源

   - 缺点是记录命令使得 aof 文件体积很大, 并且重启后的恢复速度比较慢

     

3. 混合持久化, Redis4.0 开始支持混合持久化, 结合了 RDB 和 AOF, 就是使用 RDB 做全量备份, AOF 做增量备份. RDB 以一定的频率执行, 在两次 RDB 之间用 AOF 记录这期间的所有命令. 这样就避免了频繁的 RDB 备份, 并且 AOF 只记录两次 RDB 之间的命令, 文件也不会过大.

   - 持久化时将数据都存入 aof 文件, 文件的前半部分是二进制的 RDB 格式, 后半部分是 aof 命令, 下次 RDB 时覆盖之前的日志.
   - 缺点是与旧版本不兼容



#### RDB 的触发方式?

RDB 有两种触发方式, 手动触发和自动触发

手动触发: 

- save 命令: 阻塞主线程, 直到 RDB 完成, 如果内存数据较大的话会造成长时间的阻塞, 不建议使用
- bigsave 命令: 主进程会 fork 一个子进程来执行 RDB 操作, 子进程和主进程共享内存, 主进程使用 CopyOnWrite 的方式执行 RDB 期间的命令.(主进程写数据时创建数据副本). 虽然子进程执行 RDB 不会影响到主进程, fork 的过程中主进程是会阻塞的, 频繁的 bigsave 造成频繁的 fork 还是会长时间阻塞主进程

自动触发: 

- redis.conf 中配置 save m n, 即在 m 秒内有 n 次修改就自动触发 bigsave 操作



#### 为什么 AOF 是写后日志?

- Redis 需要高性能, 所以在写日志的时候并没有检查语法, 如果先记录日志的话, 就可能在日志中记录错误命令.
- 写后日志不会阻塞当前的鞋操作



#### 什么是 AOF 重写?

AOF 记录的是命令, 如果是对同一个 key 进行了多次操作, 记录了多条命令, 这些命令中有很多是多余的, AOF 重写就是去除 AOF 文件中的冗余命令.

#### AOF 重写过程?

`一个拷贝, 两处日志` 

1. 主进程 fork 出一个后台的子进程 bgrewriteaof, 主进程的内存会拷贝一份给子进程(其实复制的是主进程的页表, 他们是共享一份内存, 主进程写入时采用 CopyOnWrite), 子进程遍历内存数据将命令写入重写日志

2. 此时如果有新命令来不会影响子进程, 修改的是主进程的内存, 并且新的命令会记录到重写缓冲区里

3. 子进程处理完成后重写缓冲区的命令写入到重写日志里, 然后用重写日志替换旧的 aof 日志

   `重写期间旧的 aof 日志仍然是工作的`



#### AOF 重写过程会阻塞吗?

重写过程要 fork 子进程, 会阻塞.



### 缓存问题

#### Redis 如何记录 key 的过期时间?

在 Redis 数据库中有两个 dict 字典, 一个字典存储 key-value, 另一个字典存储 key-ttl



#### Redis 的过期删除策略?

Redis 使用定期删除 + 惰性删除的方式

为什么不用定时删除? 每个 key 都加定时器, 定时删除会很耗费 CPU 资源

- 惰性删除: 服务器不会主动删除数据, 只有当客户端查询某个数据时, 服务器判断数据是否过期, 如果过期则删除.

- 定期删除: 默认 100 ms 检查一次, 发现过期 key 就删除. 检查时并不是全部遍历, 而是随机抽取检查, 并且执行时间也受限制

主从模式中, 从结点不会主动删除过期数据, 主节点删除 key 后会发送一个 del 命令给从结点, 从结点在删除, 在这之间从结点仍然读的到过期数据. Redis 3.2 中, 从结点在读取数据时增加了对是否过期的判断, 如果过期就不返回给客户端。



#### Redis 的内存淘汰策略？

Redis 有三类淘汰策略：

不淘汰：

- noeviction (Redis 4.0 之后的默认策略)

在设置了过期时间的 key 中进行淘汰：

- random： volatile-random -> 有过期时间的 key 中随机挑选
- ttl:  volatile-ttl -> 在有过期时间的 key 中挑选即将要过期的
- lru:  volatile-lru -> 在有过期时间的 key 中挑选: 最近最少使用 key, 会记录最近一次访问的时间戳, 值越小越优先淘汰
- lfu:  volatile-lfu -> 在有过期时间的 key 中挑选: 最少频率使用, 会统计每个 key 的访问频率, 值越优先淘汰

在所有 key 中进行淘汰：

- random: allkeys-random -> 在所有 key 里随机挑选
- lru: allkeys-lru -> 在所有 key 中挑选最近最少使用
- lfu: allkeys-lfu -> 在所有 key 中挑选最少频率使用



#### LRU 算法的实现?

Redis 会记录每个数据最近一次访问的时间戳, 在 Redis 决定淘汰数据时, 会随机选出 N 个数据, 把它们作为候选集合, 比较这些数据的 lru 字段, 把 lru 小的字段淘汰出去. 随机读取待删除集合让 Redis 可以不用维护一个巨大的链表, 进而提高性能.



#### Redis 内存用完了会发生什么?

如果是默认的内存淘汰策略(不淘汰), 当有写操作时会返回错误信息, 但是还可以读. 如果配置了其他的淘汰策略, 发生写操作时会根据淘汰策略淘汰一部分数据.



#### 缓存穿透?

缓存穿透是指的请求数据在缓存和数据库中都不存在, 这样缓存永远不会生效, 这些请求都会打到数据库上.

解决方法有:

- 接口层面增加校验, 做一些基础的拦截

- 缓存 null 值: 如果数据库中查询不到值, 可以将不存在的 key 和 null 值关联起来, 缺点是这样会浪费空间
- 布隆过滤器: 将所有的 key 都预先加载到布隆过滤器中, 查询是先使用布隆过滤器判断, 判断存在的 key 才回去请求 Redis. 布隆过滤器类似一个哈希表, 通过一个庞大的二进制数组,用哈希的思想去判断元素是否存在于集合中. 优点是节约空间, 缺点是存在误判



#### 缓存雪崩?

缓存雪崩是指一大批 key 在同一时间过期, 这些 key 集体失效, 或者 redis 宕机, 导致大量的请求进入数据库, 给数据库造成压力

解决方法: 

- 错开过期时间: 给 key 设置过期时间的时候加上随机值, 避开在同一时间大量 key 过期的情况
- 设置热点数据永不过期

如果是 Redis 宕机

- 做服务降级和限流, 当数据库的访问量超过一定阈值的时候限制访问的请求数

- 暂停访问宕机的实例, 返回预定义的信息

  

#### 缓存击穿?

缓存击穿是指某个热点数据过期时, 并发访问量特别高, 都去查询数据库给数据库造成很大压力

解决方法:

- 热点数据永不过期
- 加锁处理, 当缓存中没有查询到数据时, 互斥的去 [查询数据库和更新缓存] 这样同一个数据只会有一个请求去访问数据库, 其他请求阻塞一段时间.`这里要用双检锁, 同单例模式`
  - `查询缓存是否为空` -是-> `获取锁` -获取成功-> `再次检查缓存是否为空` -是-> `查询数据库`



#### 如何保证 Redis 和 数据库的一致性?

- 先删除缓存在更新数据库
  - 问题: 删除缓存后, 有另一个线程读缓存没读到去读数据库, 取到了还没更新的数据添加到缓存中



- 延时双删: 先删除缓存在更新数据库,更新后间隔一定时间再去删除一次缓存

  - 它解决了先删除缓存再更新数据库的过程中有其他线程更改缓存的问题, 延时删除是防止因为阻塞等原因造成第二次删除缓存后之前读取脏数据的线程才来写入缓存. `出差错的时间集中在第一次删除和查数据库的这段时间, 去查到的是脏数据`

    

- 先更新数据库再删除缓存

  - 问题: 过期的 key 被删除了, 有个请求访问缓存失败, 去数据库读取数据, 在它把数据写到缓存之前

    另一个线程更新了数据库并检查了缓存, 它在这之后才把数据写到缓存中, 造成了不一致, 但是概率比较小 `更新数据库到删除缓存这中间查询的数据不一致`



### Redis 事务



#### 什么是 Redis 事务?

Redis 事务本质上是一组命令的集合, 使用 multi 开启事务, exec 执行事务操作, discard 取消事务, watch 监视一个或多个 key, 如果这个 key 被修改则事务中断. Redis 的事务不支持回滚.

事务执行过程: 

- multi: 开启事务

- 命令 
- 命令  
- 命令  只是将命令加到队列中
- exec

#### Redis 如何保证原子性?

Redis 除了事务外还支持 lua 脚本, 能保证 lua 脚本执行的原子性, lua 脚本用数组来接收 key 和 参数.

```lua
eval "lua 脚本" 2(表示前 2 个是 key) key key argv
```



#### Redis 事务为什么不支持回滚?

- Redis 只会因为语法的错误导致失败, 是编程上的错误, 应该在开发时就被发现.
- 因为不需要回滚, Redis 内部保持简单且快速



### Redis 高可用

#### Redis 主从?

单节点的 Redis 的并发能力是有限的, 要进一步的提高 Redis 的并发能力, 就要搭建主从集群, 实现读写分离, 主节点用来写数据, 从结点读数据.



#### Redis 的主从复制?

主从复制分为全量复制和增量复制

当 Redis 主从第一次建立连接时, 会进行一次全量复制, 将主节点的全部数据都拷贝给从结点, 过程如下: 

- 从结点发送一个增量同步的请求(offset = -1), 主节点根据从结点的 replid 判断从结点是不是第一次建立连接, (相同的 replid 表示在同一个数据集, 每个主节点都有唯一的 replid, 从结点会继承主节点的 id), 如果是第一次建立连接主节点会返回自己的 replid. 
- 主节点执行 bigsave, 生成 RDB 文件发送给从结点, 从结点加载 RDB 文件, 在这期间新增加的命令会记录在 repl_backlog_buffer 中
- 最后主节点再把复制过程中新增加的命令发送给从结点, 从结点执行这些命令, 实现主从一致



增量复制

如果主从结点在命令传播的过程中发生了网络中断, 重新连接后如果进行全量复制的代价会很大, 因此有了增量复制的方式

- 从结点发送增量复制请求, 主节点根据偏移量 offset 判断和从结点相差了哪些数据, 从repl_backlog_buffer 中获取 offset 之后的命令, 发送给从库, 从库去执行这些命令达到一致.



- repl_backlog_buffer 是一个环形缓冲区, 里面记录着 Redis 处理过的命令日志, 根据偏移量去环形缓冲区中读取差异的命令, 如果缓冲区的数据发生了覆盖, 并且覆盖的数据从结点还没有同步, 那么从结点只能进行全量复制.

`每个从库会记录自己的 offset`



#### 为什么全量复制使用 RDB 而不是 AOF?

因为 RDB 是二进制文件, 文件很小, 而 AOF 记录命令, 文件会很大其中还可能包括冗余数据, 并且 RDB 文件的读取速度也比 AOF 文件的读取速度快, 所以使用 RDB 进行全量复制的成本最低.



#### Redis 的无磁盘主从复制?

Redis 默认是磁盘复制, 如果是较低速的磁盘, 这种操作会给主服务器带来较大压力. 无磁盘复制是指直接通过网络将 RDB 文件发送给子节点, 不使用磁盘做中间存储.



#### Redis 的主从从模式?

给主节点设置过多的从结点在进行全量复制时代价很大, 传输 RDB 文件也会占用很多网络带宽, 给主节点带来了很大压力, 所以可以采用主从从的模式. 避免了主节点频繁和从结点建立连接的开销.



#### Redis 的哨兵?

Redis 提供了哨兵机制来实现主从集群的自动故障恢复, 当主节点因为某种故障下线的时候, 哨兵会在从结点中选取一个结点当新的主节点.

哨兵的功能:

- 监控: Sentinel 会不断检查主从结点是否健康运行
- 自动故障恢复: 当发生故障时, Sentinel 会将一个从结点提升为主节点.
- 通知: Sentinel 充当客户端服务发现的来源, 故障发生时会将最新的信息推送给客户端



#### Redis 哨兵是如何监控集群的?如何判断主节点下线?

Sentinel 基于心跳机制检测服务的状态, 每隔一秒像集群中每个实例发送 ping 命令.

过程: 哨兵向主节点发送 INFO 命令, 主节点返回所有结点, 哨兵便可以监控所有结点



主观下线: 如果某个哨兵发现某个实例未在规定时间内响应, 就认为该实例主观下线

客观下线: 如果超过指定数量的哨兵都认为某个实例主观下线, 就认为该实例客观下线.



#### 如何选择新的主库?

选出主库

- 过滤掉不健康的结点
- 判断从结点的优先级, slave-priority 的值越小优先级越大, 如果值为 0, 永不参选
- 如果值相同, 判断 offset, 值越大越新, 越优先
- 也相同的话判断运行id, 越小优先级越高

选出后

- 哨兵向新的主节点发送 slaveof no one, 让它成为主节点
- 哨兵向其他从结点发送 slaveof ip port 命令, 让它们成为新的主节点的从结点
- 最后把旧的主节点标记为从结点, 故障恢复后成为一个从结点



#### Redis 哨兵的选举机制?

- 在哨兵集群中选举一个主的哨兵结点作为执行者, 当某个哨兵发现主节点主观下线时, 向其他哨兵发送 is-master-down-by-adder 命令, 要求将自己设为领导者
- 收到命令的哨兵如果没有同意过其他哨兵的请求, 就同意该请求
- 该哨兵发现自己的票数大于等于阈值时就将成为领导者
- 如果没选举出来将进行下一轮选举



#### 了解 Redis 分片集群吗?

Redis 分片集群主要用来解决高并发写的场景, 分片集群中有多个主节点, 每个结点保存不同的数据, 都可以配置从结点, 主节点之间通过 ping 互相检测健康状态, 客户端可以访问任意结点, 都会被转发到正确的结点.



#### Redis 哈希插槽?

Redis 集群使用的是哈希槽的概念, Redis 的分片集群有 16384 (2^14) 个哈希插槽, 每个主节点负责一部分插槽, 数据的 key 不是和结点绑定, 而是和插槽绑定, redis 根据 key 的有效信息计算插槽值.`包含{}的, {} 内是有效信息, 不包含{}, 都是有效信息`

- 为什么是 16384 个插槽
  - redis 集群的数据不会特别庞大, 哈希槽越多发送的心跳包也会越大, Redis 官方不建议超过 1000 个, 所以没必要设的太大



#### 集群的问题?

- 集群中一个插槽不可用, 整个集群都将瘫痪
- 集群数量太多心跳包太大占用网络带宽
- 命令的兼容问题, 批处理命令的 key 必须落在一个插槽上
- 集群不能运行 lua 脚本和事务, 因为 key 可能不落在同一个插槽中, 无法保证原子性



### 使用场景



#### Redis 的批量处理?

Redis 可以利用管道 Pipeline 做批处理操作, 如果是集群下的批处理命令必须保证所有的 key 都在同一个插槽内



#### Redis 分布式锁了解吗?

使用命令 setnx key value 可以实现分布式锁

- 如果 key 插入成功表示获取到了锁, 其他线程插入失败就无法获取到锁. 

- 释放锁的话使用 del key 或者设置超时时间超时自动释放

但是直接使用 setnx 会有锁误删的问题, 线程阻塞导致锁到期, 其他线程获取锁后可能会被当前线程认为是自己的锁而误删. 所以在 setnx 时 value 可以设一个唯一标识. 在删除锁的时候判断一下当前锁是不是自己的.

设置唯一标识后还是存在一定问题, 因为从判断到删除的操作并不是原子的, 改进是通过 lua 脚本使得判断和删除锁的过程是原子的.

`set nx 保证互斥, set ex 避免死锁, lua 脚本保证原子性`

问题: 主从问题(主节点写完后宕机, 从结点没数据), 集群环境 lua 和事务都不生效, `命令都不在一个结点上`

- Redisson 框架
  - Redisson 框架实现了锁续期, 可重入, 主从一致功能



#### Redis key 的设计?

格式: 业务名称:数据名:id

长度尽量不超过 44 字节, 要保证可读性强, 避免 key 的冲突, 方便统一管理, 节省空间



#### Redis 怎么实现点赞功能?

一个人只能点赞一次, 使用 set 集合可以保证数据的唯一性, 每次点赞前查询 set 集合中是否含有点赞数据, 没有的话加入将当前用户加入 set 集合内, 取消点赞的话将当前用户从集合中移除即可.

如果要同步到数据库的话, 可以直接使用一个 hash 类型来存储点赞信息, key 是被点赞的 id, field 是点赞 id, value 是否点赞的信息, 点赞是判断 hash 中是否有此元素, 没有的话直接添加, 有的话判断为 0 则改为 1. 取消点赞也是同理. 再设置定时任务, 定期将数据同步到数据库中.



#### Redis 怎么实现关注功能?

因为关注是不能重复的, 可以使用 set 来存储关注列表, 并且使用 set 取交集还能实现共同关注功能. 关注一般来说不是很频繁的一个操作, 所以在写的时候可以缓存和数据库同时写, 读的时候读缓存.



#### Redis 做一个排行榜?

使用 zset 可以实现排行榜功能.

 

#### String 的应用场景?

- 可以做一个计数器
- 存储常规数据, 比如 token, session 等
- 分布式锁



#### Hash 的应用场景?

对象存储时, 可以将对象的属性划分为 hash 的一个 field 和 value 来存储, 方便修改.



#### List 的应用场景?

- 简单的消息队列, 只要限制一下一边 push 另一边 pop 即可.
- 最新消息列表. 通过 lpush 命令在头部添加数据, 但是 list 分页可能导致出现重复数据(获取后顶部添加了一个元素, 下标变了). 所以适合每次固定获取前 n 个数据的场景.



#### Set 应用场景?

- 不能有重复数据的场景, 关注列表, 点赞信息等.
- 对多个数据集求交集,并集的场景.
- 随机获取某个数据(抽奖系统), spop -> 随机获取并移除 srandmember -> 随机获取不移除

#### Zset 应用场景?

- 各种排行榜
- 信息流展示, 可以避免重复